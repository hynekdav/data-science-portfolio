{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple classifier on Carvana dataset\n",
    "\n",
    "* The challenge of this project is to predict if the car purchased at the Auction is a good / bad buy.\n",
    "* All the variables in the data set are defined in the file Carvana_Data_Dictionary.txt \n",
    "* The data contains missing values \n",
    "* The dependent variable (IsBadBuy) is binary (C2)\n",
    "* There are 32 Independent variables (C3-C34)\n",
    "\n",
    "Used dataset: https://www.kaggle.com/c/DontGetKicked/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset = pd.read_csv('training.csv', sep=',')\n",
    "dataset.PurchDate = pd.to_datetime(dataset.PurchDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df, column):\n",
    "    zscores = np.abs(zscore(df[column]))\n",
    "    return df[zscores > 3].index\n",
    "\n",
    "def clean_data(df, columns):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    for column in columns:\n",
    "        df_copy = df_copy.drop(detect_outliers(df_copy, column), axis = 0).reset_index(drop=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VehicleAge', 'VehYear', 'VehOdo', 'MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', 'VehBCost', 'WarrantyCost']\n",
    "\n",
    "dataset = clean_data(dataset, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['RefId', 'PRIMEUNIT', 'AUCGUART', 'BYRNO', 'WheelTypeID', 'TopThreeAmericanName', 'Model', 'Trim', 'SubModel', 'VNZIP1']\n",
    "\n",
    "dataset = dataset.drop(to_drop, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nans(df):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    # fill snon numerical values with 'UNKNOWN'\n",
    "    df_copy.Color = df_copy.Color.fillna('UNKNOWN')\n",
    "    df_copy.WheelType = df_copy.WheelType.fillna('UNKNOWN')\n",
    "    df_copy.Transmission = df_copy.Transmission.fillna('UNKNOWN')\n",
    "    df_copy.Transmission = df_copy.Transmission.apply(str.upper)\n",
    "    df_copy.Nationality = df_copy.Nationality.fillna('UNKNOWN')\n",
    "    df_copy.Size = df_copy.Size.fillna('UNKNOWN')\n",
    "    \n",
    "    cols = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice']\n",
    "\n",
    "    for col in cols:\n",
    "        df_copy[col] = df_copy[col].fillna(df_copy[col].mean())\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "dataset = handle_nans(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(dataset.corr(), fmt = \".2f\", cmap = \"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = dataset.copy(deep=True)\n",
    "df['PurchDateAgg'] = df.PurchDate.apply(lambda n: f'{n.year}-{n.month}') \n",
    "\n",
    "g = sns.catplot(x='PurchDateAgg', y='IsBadBuy', data=df, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Auction', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Make', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Color', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Transmission', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='WheelType', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Nationality', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Size', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='VNST', y='IsBadBuy', data=dataset, aspect=3, kind=\"bar\")\n",
    "g.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='IsOnlineSale', y='IsBadBuy', data=dataset, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date):\n",
    "    return f'{date.year}-{date.month}'\n",
    "\n",
    "dataset['PurchDateAgg'] = dataset.PurchDate.apply(convert_date)\n",
    "dataset = dataset.drop('PurchDate', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_to_one_hot(df, column):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    one_hot = pd.get_dummies(df_copy[column], prefix=column)\n",
    "    df_copy = df_copy.join(one_hot)\n",
    "    df_copy = df_copy.drop(column, axis='columns')\n",
    "    return df_copy\n",
    "\n",
    "def convert_columns_to_one_hot(df, columns):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    for column in columns:\n",
    "        df_copy = convert_column_to_one_hot(df_copy, column)\n",
    "    return df_copy\n",
    "\n",
    "columns_to_convert = ['Auction', 'Make', 'Color', 'Transmission', 'WheelType', 'Nationality', 'Size', 'VNST', 'PurchDateAgg']\n",
    "\n",
    "dataset.IsOnlineSale = dataset.IsOnlineSale.astype(bool)\n",
    "dataset.VehBCost = dataset.VehBCost.astype(np.int)\n",
    "dataset = convert_columns_to_one_hot(dataset, columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dataset.columns)[1:]\n",
    "labels = ['IsBadBuy']\n",
    "\n",
    "X = dataset[cols]\n",
    "Y = dataset[labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier, MLPClassifier]\n",
    "params = {\n",
    "    DecisionTreeClassifier: {'max_depth': list(range(1, len(cols), 10))}, \n",
    "    RandomForestClassifier: {'n_estimators': [100, 250, 500, 1000], 'max_depth': [11]}, # max depth was found empirically so training doesn't take too long\n",
    "    GradientBoostingClassifier: {'n_estimators': [100, 250, 500, 1000]},\n",
    "    MLPClassifier: {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)], 'activation': ['tanh', 'relu'], 'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate': ['constant','adaptive'], 'early_stopping': [True], 'max_iter': [100]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beware, `find_best_models` runs about 25 mins on 6 core CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def find_best_models(models, params):\n",
    "    best_estimators = []\n",
    "    for model in models:\n",
    "        print(f'{model}')\n",
    "        clf = GridSearchCV(model(), params[model], scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)\n",
    "        clf.fit(X_train, y_train.values.ravel())\n",
    "        best_estimators.append(clf.best_estimator_)\n",
    "    return best_estimators\n",
    "\n",
    "best_models = find_best_models(models, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f'Evaluating model: {model.__class__.__name__}')\n",
    "    plot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n",
    "    plot_roc_curve(model, X_test, y_test)\n",
    "    plt.show()\n",
    "    print('-----------')\n",
    "\n",
    "for model in best_models:\n",
    "    evaluate_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
