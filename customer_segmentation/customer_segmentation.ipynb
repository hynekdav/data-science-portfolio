{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer segmentation\n",
    "\n",
    "**RFM** approach to segment customers of an eshop into similar clusters using K-means, Agglomerative Clustering and Gaussian Mixture models.\n",
    "\n",
    "**RFM** stands for:\n",
    "- **R**ecency: Days since the customer made their last order.\n",
    "- **F**requency: Total number of purchases made by the customer.\n",
    "- **M**onetary: Sum of money the customer had spent in the eshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import seaborn as sns; sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"eshop.csv\")\n",
    "df.Date = pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFM data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = df.Date.max()\n",
    "\n",
    "rfm = df.groupby(['CustomerID']).agg({\n",
    "        'Date': lambda x: (today - x.max()).days,\n",
    "        'CustomerID': 'count', \n",
    "        'Subtotal': 'sum'})\n",
    "\n",
    "rfm = rfm.rename({'Date': 'Recency', 'CustomerID': 'Frequency', 'Subtotal': 'Monetary'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(rfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on scaling \n",
    "We need to scale the dataset in order to reduce great differences between variables (eg frequency will almost always be many times smaller than recency or monetary). I decided to go with the standard scaler, as it produced best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,20)\n",
    "for k in K:\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('clusterer', KMeans(n_clusters=k))])\n",
    "    pipeline.fit(rfm.values)\n",
    "    distortions.append(pipeline[-1].inertia_)\n",
    "\n",
    "chart = sns.lineplot(x=K, y=distortions)\n",
    "chart.set_title('Elbow method for getting K')\n",
    "chart.set_xlabel('Number of clusters - K')\n",
    "chart.set_ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters can be decided using many methods, such as the elbow method. In our case it seems the \"elbow\" is with `K = 3`, so I'll go with it and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('clusterer', KMeans(n_clusters=K))])\n",
    "pipeline.fit(rfm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = pipeline[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_rfm = rfm.copy(deep=True)\n",
    "clustered_rfm['CustomerCategory'] = pipeline[-1].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in range(pipeline[-1].n_clusters):\n",
    "    description = clustered_rfm[clustered_rfm.CustomerCategory == i].describe()\n",
    "    clusters.append(description)\n",
    "    display(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstars_id = max(zip(map(lambda cluster: cluster.loc['mean', 'Monetary'], clusters), range(len(clusters))))[1]\n",
    "losers_id = max(zip(map(lambda cluster: cluster.loc['mean', 'Recency'], clusters), range(len(clusters))))[1]\n",
    "normies_id = list(set([0, 1, 2]) - set([superstars_id, losers_id]))[0]\n",
    "\n",
    "print(f'Superstar customers cluster: {superstars_id}.')\n",
    "print(f'Normal customers cluster: {normies_id}.')\n",
    "print(f'Uninteresting customers cluster: {losers_id}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('clusterer', AgglomerativeClustering(n_clusters=K))])\n",
    "pipeline.fit(rfm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_rfm = rfm.copy(deep=True)\n",
    "clustered_rfm['CustomerCategory'] = pipeline[-1].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in range(pipeline[-1].n_clusters):\n",
    "    description = clustered_rfm[clustered_rfm.CustomerCategory == i].describe()\n",
    "    clusters.append(description)\n",
    "    display(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstars_id = max(zip(map(lambda cluster: cluster.loc['mean', 'Monetary'], clusters), range(len(clusters))))[1]\n",
    "losers_id = max(zip(map(lambda cluster: cluster.loc['mean', 'Recency'], clusters), range(len(clusters))))[1]\n",
    "normies_id = list(set([0, 1, 2]) - set([superstars_id, losers_id]))[0]\n",
    "\n",
    "print(f'Superstar customers cluster: {superstars_id}.')\n",
    "print(f'Normal customers cluster: {normies_id}.')\n",
    "print(f'Uninteresting customers cluster: {losers_id}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixture\n",
    "I'm using this algorithm just out of curiosity to see if the customers are \"generated\" with respect to Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('clusterer', GaussianMixture(n_components=K))])\n",
    "pipeline.fit(rfm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_rfm = rfm.copy(deep=True)\n",
    "clustered_rfm['CustomerCategory'] = pipeline[-1].predict(rfm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in range(pipeline[-1].n_components):\n",
    "    description = clustered_rfm[clustered_rfm.CustomerCategory == i].describe()\n",
    "    clusters.append(description)\n",
    "    display(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the `GaussianMixture` doesn't work in this case (most likely because customers are not generated from Gaussian distribution). I was just curious to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Turns out that both `KMeans` and `AgglomerativeClustering` work well in this case and are able to correctly identify all `3` clusters correctly (more or less), while `GaussianMixture` only identified `2` clusters (still correctly, but `2` none the less...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# borrowed from https://gist.github.com/clintval/e9afc246e77f6488cda79f86e4d37148\n",
    "def silhouette_plot(X, y, n_clusters, ax=None):\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    silhouette_avg = silhouette_score(X, y)\n",
    "    sample_silhouette_values = silhouette_samples(X, y)\n",
    "\n",
    "    y_lower = padding = 2\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[y == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        \n",
    "        cmap = cm.get_cmap(\"tab10\")\n",
    "        color = cmap(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                         0,\n",
    "                         ith_cluster_silhouette_values,\n",
    "                         facecolor=color,\n",
    "                         edgecolor=color,\n",
    "                         alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + padding\n",
    "\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhoutte score of all the values\n",
    "    ax.axvline(x=silhouette_avg, c='r', alpha=0.8, lw=0.8, ls='-')\n",
    "    ax.annotate('Average',\n",
    "                xytext=(silhouette_avg, y_lower * 1.025),\n",
    "                xy=(0, 0),\n",
    "                ha='center',\n",
    "                alpha=0.8,\n",
    "                c='r')\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    ax.set_ylim(0, y_upper + 1)\n",
    "    ax.set_xlim(-0.075, 1.0)\n",
    "    ax.figure.set_size_inches(10, 15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_plot(rfm.values, kmeans.labels_, n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "From the silhouette chart it can be seen that as predicted the cluster of \"superstars\" is smallest one, normal customers cluster is the greatest and uninteresting are somewhere in between.\n",
    "\n",
    "Given the fact how many elements in each cluster have silhouette score smaller than 0, we can suppose that the number of clusters was chosen correctly. Only the cluster of \"superstars\" has more elements with silhouette score smaller than zero, than the others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
